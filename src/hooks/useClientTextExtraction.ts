import { logger } from '@/utils/logger';

import { useState } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { toast } from '@/hooks/use-toast';
import { analyzeDocumentWithAI, updateDocumentWithAnalysis } from '@/services/documentAnalysisService';
import * as pdfjsLib from 'pdfjs-dist';
import * as XLSX from 'xlsx';

// Use a CDN that actually works for PDF.js worker
pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://unpkg.com/pdfjs-dist@4.8.69/build/pdf.worker.min.mjs';

interface TextExtractionResult {
  text: string;
  method: string;
  aiAnalysis?: string;
}

export const useClientTextExtraction = () => {
  const [isExtracting, setIsExtracting] = useState<Record<string, boolean>>({});

  const extractTextFromPDF = async (file: File): Promise<string> => {
    try {
      logger.log('üîÑ Starting PDF text extraction for:', file.name);
      const arrayBuffer = await file.arrayBuffer();
      
      const loadingTask = pdfjsLib.getDocument({ 
        data: arrayBuffer,
        verbosity: 0,
        isOffscreenCanvasSupported: false // Disable offscreen canvas for better compatibility
      });
      
      const pdf = await loadingTask.promise;
      logger.log('üìÑ PDF loaded successfully, pages:', pdf.numPages);
      
      let fullText = '';

      for (let i = 1; i <= pdf.numPages; i++) {
        try {
          const page = await pdf.getPage(i);
          const textContent = await page.getTextContent();
          const pageText = textContent.items
            .filter(item => 'str' in item)
            .map(item => (item as any).str)
            .join(' ');
          
          if (pageText.trim()) {
            fullText += pageText + '\n\n';
          }
          
          logger.log(`üìñ Extracted text from page ${i}: ${pageText.length} characters`);
        } catch (pageError) {
          console.warn(`‚ö†Ô∏è Could not extract text from page ${i}:`, pageError);
          // Continue with other pages
        }
      }

      const cleanText = fullText.trim();
      
      if (cleanText.length < 10) {
        throw new Error('PDF ser ut til √• v√¶re scannet eller inneholder lite tekst. Pr√∏ver backend-prosessering...');
      }
      
      logger.log('‚úÖ PDF text extraction completed:', cleanText.length, 'characters');
      return cleanText;
      
    } catch (error) {
      logger.error('‚ùå PDF extraction error:', error);
      throw new Error('Frontend PDF-lesing feilet. Sender til backend for avansert prosessering...');
    }
  };

  const extractTextFromExcel = async (file: File): Promise<string> => {
    try {
      logger.log('üìä Starting Excel text extraction for:', file.name);
      const arrayBuffer = await file.arrayBuffer();
      const workbook = XLSX.read(arrayBuffer, { type: 'array' });
      let fullText = '';

      workbook.SheetNames.forEach(sheetName => {
        const worksheet = workbook.Sheets[sheetName];
        const csvData = XLSX.utils.sheet_to_csv(worksheet);
        if (csvData.trim()) {
          fullText += `--- ${sheetName} ---\n${csvData}\n\n`;
        }
      });

      const cleanText = fullText.trim();
      logger.log('‚úÖ Excel extraction completed:', cleanText.length, 'characters');
      return cleanText;
      
    } catch (error) {
      logger.error('‚ùå Excel extraction error:', error);
      throw new Error('Kunne ikke lese Excel-innhold');
    }
  };

  const extractTextFromFile = async (file: File): Promise<string> => {
    logger.log('üîç Extracting text from file:', file.name, 'type:', file.type);
    
    if (file.type === 'application/pdf') {
      return await extractTextFromPDF(file);
    } else if (
      file.type.includes('spreadsheet') || 
      file.type.includes('excel') ||
      file.type === 'text/csv' ||
      file.name.endsWith('.xlsx') ||
      file.name.endsWith('.xls')
    ) {
      return await extractTextFromExcel(file);
    } else if (file.type.startsWith('text/')) {
      const text = await file.text();
      logger.log('üìù Text file extracted:', text.length, 'characters');
      return text;
    } else {
      throw new Error('Filtype st√∏ttes ikke for tekstekstraksjon');
    }
  };

  const callBackendExtraction = async (documentId: string): Promise<boolean> => {
    try {
      logger.log('üîÑ Calling backend extraction for document:', documentId);
      
      // Update status to indicate backend processing
      await supabase
        .from('client_documents_files')
        .update({ 
          text_extraction_status: 'processing',
          extracted_text: '[Backend prosessering startet...]'
        })
        .eq('id', documentId);

      // Call the enhanced PDF text extractor edge function
      const { data, error } = await supabase.functions.invoke('enhanced-pdf-text-extractor', {
        body: { documentId }
      });

      if (error) {
        logger.error('‚ùå Backend extraction failed:', error);
        throw new Error(`Backend-prosessering feilet: ${error.message}`);
      }

      logger.log('‚úÖ Backend extraction completed successfully:', data);
      return true;
      
    } catch (error) {
      logger.error('‚ùå Backend extraction error:', error);
      
      // Update with failed status
      await supabase
        .from('client_documents_files')
        .update({ 
          text_extraction_status: 'failed',
          extracted_text: `[Backend ekstrasjon feilet: ${error.message}]`
        })
        .eq('id', documentId);
      
      return false;
    }
  };

  const generateAIAnalysis = async (
    text: string,
    fileName: string,
    documentId: string
  ): Promise<string> => {
    try {
      logger.log('ü§ñ Generating AI analysis for document:', fileName);

      const result = await analyzeDocumentWithAI({
        documentId,
        fileName,
        extractedText: text,
        clientId: ''
      });

      await updateDocumentWithAnalysis(result);

      logger.log('‚úÖ AI analysis completed:', result.aiAnalysisSummary.substring(0, 100) + '...');
      return result.aiAnalysisSummary;

    } catch (error) {
      logger.error('AI analysis error:', error);
      return '';
    }
  };

  const extractAndAnalyzeDocument = async (documentId: string): Promise<boolean> => {
    if (isExtracting[documentId]) return false;
    
    setIsExtracting(prev => ({ ...prev, [documentId]: true }));

    try {
      // Get document info
      const { data: document, error: docError } = await supabase
        .from('client_documents_files')
        .select('*')
        .eq('id', documentId)
        .single();

      if (docError || !document) {
        throw new Error('Kunne ikke finne dokument');
      }

      logger.log('üìã Processing document:', document.file_name, 'type:', document.mime_type);

      // Check if document already has error text and needs re-processing
      const hasErrorText = document.extracted_text?.includes('[OpenAI Vision feilet') || 
                          document.extracted_text?.includes('[Kunne ikke') ||
                          document.extracted_text?.includes('Maximum call stack size');

      if (hasErrorText) {
        logger.log('üîÑ Document has error text, re-processing with improved method...');
      }

      // Update status to processing
      await supabase
        .from('client_documents_files')
        .update({ text_extraction_status: 'processing' })
        .eq('id', documentId);

      // Download file
      const { data: fileData, error: downloadError } = await supabase.storage
        .from('client-documents')
        .download(document.file_path);

      if (downloadError || !fileData) {
        throw new Error('Kunne ikke laste ned fil');
      }

      // Convert Blob to File
      const file = new File([fileData], document.file_name, {
        type: document.mime_type,
        lastModified: Date.now(),
      });

      let extractedText = '';
      let extractionMethod = 'Frontend ekstrasjon';
      let shouldFallbackToBackend = false;

      try {
        // Try frontend extraction first
        extractedText = await extractTextFromFile(file);
        
        if (!extractedText || extractedText.trim().length < 10) {
          logger.log('‚ö†Ô∏è Frontend extraction produced minimal text, trying backend...');
          shouldFallbackToBackend = true;
        }
        
      } catch (frontendError) {
        logger.log('‚ö†Ô∏è Frontend extraction failed:', frontendError.message);
        
        // For PDFs and other supported files, try backend extraction
        if (document.mime_type === 'application/pdf' || 
            document.mime_type.includes('excel') || 
            document.mime_type.includes('spreadsheet')) {
          logger.log('üîÑ Switching to backend extraction...');
          shouldFallbackToBackend = true;
        } else {
          // For non-supported files, fail immediately
          throw frontendError;
        }
      }

      // If we need to fallback to backend
      if (shouldFallbackToBackend) {
        logger.log('üîÑ Initiating backend fallback...');
        const success = await callBackendExtraction(documentId);
        
        if (success) {
          toast({
            title: "Backend-prosessering startet",
            description: `Dokumentet "${document.file_name}" sendes til backend for avansert tekstekstraksjon`,
          });
        } else {
          toast({
            title: "Prosessering feilet",
            description: `Kunne ikke prosessere "${document.file_name}"`,
            variant: "destructive"
          });
        }
        
        return success;
      }

      // If we have text from frontend extraction
      if (extractedText && extractedText.trim().length >= 10) {
        // Generate AI analysis using our new edge function
        await generateAIAnalysis(extractedText, document.file_name, documentId);

        const { error: updateError } = await supabase
          .from('client_documents_files')
          .update({
            extracted_text: extractedText,
            text_extraction_status: 'completed',
            updated_at: new Date().toISOString()
          })
          .eq('id', documentId);

        if (updateError) {
          throw new Error('Kunne ikke lagre resultater');
        }

        toast({
          title: "Tekstekstraksjon fullf√∏rt!",
          description: `${extractedText.length} tegn ekstraktert fra ${document.file_name}`,
        });

        return true;
      } else {
        throw new Error('Ingen tekst ekstraktert fra dokument');
      }

    } catch (error) {
      logger.error('‚ùå Text extraction error:', error);
      
      // Update status to failed
      await supabase
        .from('client_documents_files')
        .update({ 
          text_extraction_status: 'failed',
          extracted_text: `[Tekstekstraksjon feilet: ${error.message}]`
        })
        .eq('id', documentId);

      toast({
        title: "Tekstekstraksjon feilet",
        description: error.message,
        variant: "destructive"
      });

      return false;
    } finally {
      setIsExtracting(prev => ({ ...prev, [documentId]: false }));
    }
  };

  return {
    extractAndAnalyzeDocument,
    isExtracting
  };
};
